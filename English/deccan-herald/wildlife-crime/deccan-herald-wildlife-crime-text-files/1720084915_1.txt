Artificial intelligence (AI) is gearing up to alert the police on crimes, be it a molestation incident on a city street or a violent protest.ADVERTISEMENTResearchers from two Indian institutes and the University of Cambridge, who created quite a stir with their AI-based drone platform for monitoring violent behaviour in people, plan to integrate CCTV cameras for monitoring crimes. The image of a human body is divided into 14 units to analyse the pose of an individual in real time for signs of aggression and violence. Backed by artificial intelligence, the system "learns" to recognise more violent poses over time. The project came to the fore following the publication of 'Eye in the Sky', a research paper by Amarjot Singh from the Department of Engineering in the University of Cambridge, United Kingdom; Devendra Patil from the National Institute of Technology, Warangal; and S N Omkar from the Indian Institute of Science, Bengaluru.Omkar stressed the need for such a surveillance system to check the spread of violence, especially during protests and riots. "Until now, drones were used for video monitoring and detection of crime depended on the sharpness of the human eye. Now, AI will red-flag the behaviour found to be violent or criminal," he said. The January 2017 incident of two men molesting a woman and throwing her to the ground that was caught on CCTV cameras was one of the incidents that inspired the researchers. "An integrated CCTV camera network backed by our system can alert the police immediately," she said. "It can check chain-snatching, robbery, molestation of women and similar crimes," he said.More tests awaited At present, the system has an accuracy of 84.44% even in environments specifically set up for trials. The researchers are yet to test it in real time."We have obtained permission from the authorities for testing it at a campus festival at the NIT, Warangal. We will know the results soon," Singh told DH from London.Experts have already aired concerns about the dangers posed by the surveillance system considering its potential for misuse in suppressing dissent. Singh acknowledged the concerns, but said they were overstated. "Those who are protesting against surveillance should know they are already in it. Throughout the history of science, we see the fear of misuse at every stage. That should not stop us at a time when incidents of terrorism and riots are on the rise," he said.Asked about the challenges for the system in dynamic environments like a street in Bengaluru, Singh said the systems were still evolving. "If molestation happens in a different way than the one system recognises, the system will learn these complexities over time," he said.